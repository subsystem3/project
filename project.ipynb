{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brand Sentiment Analysis of Twitter Posts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PULL FROM GIT LARGE FILE STORAGE (LFS)\n",
    "!git lfs pull --include=\"datasets/*\"\n",
    "!git lfs pull --include=\"cache/*\"\n",
    "!git lfs pull --include=\"*.mp4\"\n",
    "!git lfs pull --include=\"Final-Project-Team-2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE PROJECT VISUALIZATIONS/ARTIFACTS IN THE REPORT DIRECTORY\n",
    "os.makedirs(\"report\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"\n",
    "    A class to hold metrics for monitoring performance.\n",
    "\n",
    "    This class is a singleton, meaning that there is only one instance of the class throughout the entire program.\n",
    "    All functions decorated with @measure_time share the same Metrics object.\n",
    "\n",
    "    Attributes:\n",
    "        metrics (dict): A dictionary to store the metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls):\n",
    "        \"\"\"\n",
    "        Overrides the default object creation method to implement the singleton pattern.\n",
    "\n",
    "        Returns:\n",
    "            Metrics: The singleton instance of the Metrics class.\n",
    "        \"\"\"\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Metrics, cls).__new__(cls)\n",
    "            cls._instance.metrics = {}\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the Metrics class with an empty dictionary.\"\"\"\n",
    "        self.metrics: dict[str, float] = {}\n",
    "\n",
    "    def add_metric(self, key: str, value: float) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new metric to the dictionary or appends to an existing one.\n",
    "\n",
    "        Args:\n",
    "            key (str): The name of the metric.\n",
    "            value (float): The value of the metric.\n",
    "        \"\"\"\n",
    "        if key in self.metrics:\n",
    "            self.metrics[key] += value\n",
    "        else:\n",
    "            self.metrics[key] = value\n",
    "\n",
    "    def get_metrics(self) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Returns the dictionary of metrics.\n",
    "\n",
    "        Returns:\n",
    "            dict: The dictionary of metrics.\n",
    "        \"\"\"\n",
    "        return self.metrics\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Returns a string representation of the metrics.\"\"\"\n",
    "        return \"\\n\".join(f\"{k}: {v}\" for k, v in self.metrics.items())\n",
    "\n",
    "    def __getitem__(self, key: str) -> float:\n",
    "        \"\"\"\n",
    "        Returns the value of the metric with the given key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the metric.\n",
    "\n",
    "        Returns:\n",
    "            float: The value of the metric.\n",
    "        \"\"\"\n",
    "        return self.metrics.get(key)\n",
    "\n",
    "    def __setitem__(self, key: str, value: float) -> None:\n",
    "        \"\"\"\n",
    "        Sets the value of the metric with the given key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the metric.\n",
    "            value (float): The value of the metric.\n",
    "        \"\"\"\n",
    "        self.metrics[key] = value\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of metrics.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of metrics.\n",
    "        \"\"\"\n",
    "        return len(self.metrics)\n",
    "\n",
    "    def __contains__(self, key: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the metric with the given key exists.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the metric.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the metric exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return key in self.metrics\n",
    "\n",
    "    def clear_metrics(self) -> None:\n",
    "        \"\"\"Clears all the metrics.\"\"\"\n",
    "        self.metrics.clear()\n",
    "\n",
    "    def remove_metric(self, key: str) -> None:\n",
    "        \"\"\"\n",
    "        Removes the metric with the given key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the metric.\n",
    "        \"\"\"\n",
    "        if key in self.metrics:\n",
    "            del self.metrics[key]\n",
    "\n",
    "    def update_metric(self, key: str, value: float) -> None:\n",
    "        \"\"\"\n",
    "        Updates the value of the metric with the given key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the metric.\n",
    "            value (float): The new value of the metric.\n",
    "        \"\"\"\n",
    "        if key in self.metrics:\n",
    "            self.metrics[key] = value\n",
    "\n",
    "    def print_metrics(self) -> None:\n",
    "        \"\"\"Prints all the metrics in a nice format.\"\"\"\n",
    "        print(\"Metrics:\")\n",
    "        sorted_metrics = sorted(\n",
    "            self.metrics.items(), key=lambda item: item[1], reverse=True\n",
    "        )\n",
    "        for key, value in sorted_metrics:\n",
    "            print(f\"  {key}: {value:.2f} seconds\")\n",
    "        print(f\"Total time: {sum(self.metrics.values()):.2f} seconds\")\n",
    "\n",
    "\n",
    "def measure_time(run_name: str):\n",
    "    \"\"\"\n",
    "    A decorator factory that measures the time taken by a function and logs it to the Metrics singleton.\n",
    "\n",
    "    Args:\n",
    "        run_name (str): The name of the run. This is used to differentiate metrics among different runs.\n",
    "\n",
    "    Returns:\n",
    "        Callable: The decorator that wraps the function with timing and logging.\n",
    "    \"\"\"\n",
    "\n",
    "    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "        \"\"\"\n",
    "        The actual decorator that wraps the function with timing and logging.\n",
    "\n",
    "        Args:\n",
    "            func (Callable): The function to be timed and logged.\n",
    "\n",
    "        Returns:\n",
    "            Callable: The wrapped function.\n",
    "        \"\"\"\n",
    "\n",
    "        def wrapper(*args, **kwargs):\n",
    "            \"\"\"\n",
    "            The wrapper function that adds timing and logging to the original function.\n",
    "\n",
    "            Args:\n",
    "                *args: The positional arguments for the original function.\n",
    "                **kwargs: The keyword arguments for the original function.\n",
    "\n",
    "            Returns:\n",
    "                The result of the original function.\n",
    "            \"\"\"\n",
    "            # START TIMER\n",
    "            start_time = time.time()\n",
    "            # CALL FUNCTION\n",
    "            result = func(*args, **kwargs)\n",
    "            # CALCULATE ELAPSED TIME\n",
    "            total_time = time.time() - start_time\n",
    "            # LOG RESULT\n",
    "            metrics.add_metric(f\"{run_name}\", total_time)\n",
    "            print(f\"{run_name}...{total_time:.2f} seconds\")\n",
    "            return result\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Management\n",
    "\n",
    "We define a list of required packages and a function for installing them. This function, `handle_packages`, checks for each package in the system. If a package is not found, it is installed quietly using the pip package manager. \n",
    "\n",
    "By invoking `handle_packages` with the list of required packages, we make sure all project dependencies are satisfied, setting up a reliable and reproducible environment for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL REQUIRED PACKAGES FOR PROJECT\n",
    "PACKAGES = [\n",
    "    \"adjustText\",\n",
    "    \"colorama\",\n",
    "    \"dotenv\",\n",
    "    \"joblib\",\n",
    "    \"matplotlib\",\n",
    "    \"nltk\",\n",
    "    \"numpy\",\n",
    "    \"openai\",\n",
    "    \"pandas\",\n",
    "    \"preprocessor\",\n",
    "    \"python-dotenv\",\n",
    "    \"seaborn\",\n",
    "    \"sklearn\",\n",
    "    \"tqdm\",\n",
    "    \"tweet-preprocessor\",\n",
    "    \"wandb\",\n",
    "    \"wordcloud\",\n",
    "]\n",
    "\n",
    "\n",
    "@measure_time(\"installing required packages\")\n",
    "def handle_packages(packages: list) -> None:\n",
    "    \"\"\"Quietly installs a package if it is not already installed.\n",
    "\n",
    "    Args:\n",
    "        packages (list): The list of packages to install.\n",
    "\n",
    "    Raises:\n",
    "        ImportError: If the package is not installed, install it.\n",
    "    \"\"\"\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            os.system(f\"python3 -m pip install -q {package}\")\n",
    "\n",
    "\n",
    "handle_packages(PACKAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import wraps\n",
    "from pprint import pprint\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from colorama import Fore, Style\n",
    "import dotenv\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import preprocessor\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import wandb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Data Analysis and Visualization Tools\n",
    "\n",
    "We import data handling and visualization libraries and configure them for ideal display. These steps prepare our environment for efficient data analysis and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "\n",
    "# SET MATPLOTLIB STYLE TO 'fivethirtyeight'\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Environment Variables\n",
    "\n",
    "We load environment variables from a `.env` file using the `dotenv` package. This file has key-value pairs of environment variables, which are then added to the system's environment variables. This approach lets us manage sensitive information securely and consistently across different project stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ENVIRONMENT VARIABLES\n",
    "ENVIRONMENT = dotenv.dotenv_values()\n",
    "for key in ENVIRONMENT:\n",
    "    os.environ[key] = ENVIRONMENT[key]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving and Preparing the Sentiment140 Dataset\n",
    "\n",
    "The Sentiment140 dataset, available at <http://help.sentiment140.com/for-students>, is a collection of 1.6 million tweets with sentiment labels. \n",
    "\n",
    "It is used for discovering the sentiment of a brand, product, or topic on Twitter.\n",
    "\n",
    "The dataset, provided as a CSV file with emoticons removed, includes tweet content and sentiment labels. We extract these parts and remap the sentiment labels for easier interpretation in future analyses.\n",
    "\n",
    "The dataset has 6 fields:\n",
    "1. `target` — the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "1. `id` — the id of the tweet (2087)\n",
    "1. `date` — the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "1. `flag` — the query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "1. `user` — the user that tweeted (robotickilldozr)\n",
    "1. `text` — the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\n",
    "    \"datasets/training.1600000.processed.noemoticon.csv\",\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    names=[\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"tweet\"],\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "# GET TWEETS AND SENTIMENT LABELS\n",
    "tweets_df = tweets_df[[\"tweet\", \"sentiment\"]]\n",
    "\n",
    "# REMAP SENTIMENT LABELS TO 0 = negative, 1 = positive (instead of 0 = negative, 4 = positive)\n",
    "tweets_df.sentiment = tweets_df.sentiment.replace(4, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balance\n",
    "\n",
    "We ensure class balance in our dataset by counting the number of positive and negative tweets. Class balance is important because the model is trained on an equal number of instances from each class, preventing bias towards a particular sentiment. \n",
    "\n",
    "We generate a bar plot showing the distribution of sentiments in the training dataset, which indicates whether models will be trained on a balanced set of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SENTIMENT DISTRIBUTION IN TRAINING SET\n",
    "distribution = tweets_df.sentiment.value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=distribution.index, y=distribution.values)\n",
    "plt.title(\"Distribution of Sentiment in Sentiment140 Training Set\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks([0, 1], [\"Negative\", \"Positive\"])\n",
    "\n",
    "for i, v in enumerate(distribution.values):\n",
    "    # ADD COUNTS ABOVE BARS\n",
    "    plt.text(i, v, str(v), ha=\"center\")\n",
    "\n",
    "# SAVE VISUALIZATION\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"report/sentiment_distribution.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud\n",
    "\n",
    "A word cloud is a visual representation where the most often occurring words are displayed larger than less common words. This visualization gives a quick understanding of the key themes or topics in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time(\"generating word cloud from training data\")\n",
    "def generate_wordcloud(df_train):\n",
    "    \"\"\"\n",
    "    Generate a wordcloud from a dataframe.\n",
    "\n",
    "    Args:\n",
    "        df_train (DataFrame): The dataframe containing the text data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    wordcloud = WordCloud(\n",
    "        width=1600,\n",
    "        height=800,\n",
    "        background_color=\"white\",\n",
    "        min_font_size=10,\n",
    "        max_words=1000,\n",
    "        collocations=False,\n",
    "        random_state=42,  # set for idempotency\n",
    "    )\n",
    "\n",
    "    wordcloud.generate(\" \".join(df_train.tweet.tolist()))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # SAVE VISUALIZATION\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"report/wordcloud.png\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generate_wordcloud(tweets_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is a key step in Natural Language Processing (NLP) to improve the performance and accuracy of the models. The aim is to get the text data ready for machine learning algorithms. \n",
    "\n",
    "In its raw form, text data can be messy and unstructured, making it hard for a machine-learning model to understand and learn from. Preprocessing cleans up the data by removing unnecessary information like punctuation and common words that add little meaning or converting all text to lowercase so the model does not get confused by the same word in different cases. Transforming text into a clean and standardized form makes it easier for machine learning models to analyze the data and perform tasks like classification, prediction, or translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT BRANDS FROM CATEGORIES\n",
    "\n",
    "technology = [\n",
    "    \"oracle\",\n",
    "    \"ibm\",\n",
    "    \"lenovo\",\n",
    "    \"sony\",\n",
    "    \"adobe\",\n",
    "    \"apple\",\n",
    "    \"facebook\",\n",
    "    \"dell\",\n",
    "    \"microsoft\",\n",
    "    \"google\",\n",
    "    \"amazon\",\n",
    "    \"nokia\",\n",
    "    \"cisco\",\n",
    "    \"samsung\",\n",
    "    \"intel\",\n",
    "    \"asus\",\n",
    "    \"tesla\",\n",
    "    \"hp\",\n",
    "    \"lg\",\n",
    "    \"netflix\",\n",
    "]\n",
    "\n",
    "clothing = [\n",
    "    \"gap\",\n",
    "    \"adidas\",\n",
    "    \"vans\",\n",
    "    \"zara\",\n",
    "    \"puma\",\n",
    "    \"nike\",\n",
    "    \"prada\",\n",
    "    \"gucci\",\n",
    "    \"chanel\",\n",
    "]\n",
    "\n",
    "food = [\n",
    "    \"kfc\",\n",
    "    \"subway\",\n",
    "    \"chipotle\",\n",
    "    \"mcdonalds\",\n",
    "    \"dominos\",\n",
    "    \"chick-fil-a\",\n",
    "    \"starbucks\",\n",
    "    \"starburst\",\n",
    "    \"wendys\",\n",
    "]\n",
    "\n",
    "entertainment = [\n",
    "    \"hulu\",\n",
    "    \"universal\",\n",
    "    \"dc\",\n",
    "    \"showtime\",\n",
    "    \"amc\",\n",
    "    \"disney\",\n",
    "    \"cbs\",\n",
    "    \"marvel\",\n",
    "    \"starz\",\n",
    "    \"paramount\",\n",
    "    \"mgm\",\n",
    "    \"pixar\",\n",
    "    \"hbo\",\n",
    "    \"netflix\",\n",
    "]\n",
    "\n",
    "drinks = [\n",
    "    \"smirnoff\",\n",
    "    \"bacardi\",\n",
    "    \"nescafe\",\n",
    "    \"corona\",\n",
    "    \"tropicana\",\n",
    "    \"baileys\",\n",
    "    \"sprite\",\n",
    "    \"7up\",\n",
    "    \"fanta\",\n",
    "    \"heineken\",\n",
    "    \"guinness\",\n",
    "    \"gatorade\",\n",
    "    \"starbucks\",\n",
    "    \"fiji\",\n",
    "    \"coca-cola\",\n",
    "    \"pepsi\",\n",
    "]\n",
    "\n",
    "# MERGE CATEGORIES\n",
    "# BRANDS = technology + clothing + food + entertainment + drinks\n",
    "BRANDS = [\n",
    "    \"facebook\",\n",
    "    \"google\",\n",
    "    \"apple\",\n",
    "    \"starbucks\",\n",
    "    \"disney\",\n",
    "    \"microsoft\",\n",
    "    \"target\",\n",
    "    \"amazon\",\n",
    "    \"walmart\",\n",
    "    \"sony\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE FREQUENCY OF EACH BRAND IN THE TWEETS\n",
    "counter = Counter(\n",
    "    word\n",
    "    for tweet in tweets_df.tweet\n",
    "    for word in tweet.lower().split()\n",
    "    if word in BRANDS\n",
    ")\n",
    "\n",
    "# CREATE DATAFRAME FROM THE COUNTER\n",
    "brand_freqs_df = pd.DataFrame(\n",
    "    counter.items(), columns=[\"brand\", \"frequency\"]\n",
    ").sort_values(\"frequency\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE BRAND MENTION FREQUENCY\n",
    "\n",
    "# CREATE BARPLOT\n",
    "num_brands = len(brand_freqs_df)\n",
    "plt.figure(figsize=(10, num_brands * 0.5))\n",
    "barplot = sns.barplot(\n",
    "    x=\"frequency\", y=\"brand\", data=brand_freqs_df, order=brand_freqs_df.brand\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Brand Mention Frequency\")\n",
    "\n",
    "# ADD COUNTS AT THE END OF THE BARS\n",
    "for i, v in enumerate(brand_freqs_df.frequency):\n",
    "    barplot.text(v + 3, i + 0.25, str(v))\n",
    "\n",
    "# SAVE VISUALIZATION\n",
    "plt.tight_layout()\n",
    "barplot.figure.savefig(\"report/brand_mention_frequency.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = [\"technology\", \"clothing\", \"food\", \"entertainment\", \"drinks\"]\n",
    "categories = [\n",
    "    (technology, \"technology\"),\n",
    "    (clothing, \"clothing\"),\n",
    "    (food, \"food\"),\n",
    "    (entertainment, \"entertainment\"),\n",
    "    (drinks, \"drinks\"),\n",
    "]\n",
    "\n",
    "category_counts = dict.fromkeys(category_names, 0)\n",
    "\n",
    "for brand, count in counter.items():\n",
    "    for category, category_name in categories:\n",
    "        if brand in category:\n",
    "            category_counts[category_name] += count\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "category_df = pd.DataFrame.from_dict(\n",
    "    category_counts, orient=\"index\", columns=[\"frequency\"]\n",
    ").reset_index()\n",
    "category_df.columns = [\"category\", \"frequency\"]\n",
    "category_df = category_df.sort_values(\"frequency\", ascending=False).reset_index()\n",
    "\n",
    "# PLOT DATAFRAME\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.barplot(x=\"category\", y=\"frequency\", data=category_df)\n",
    "ax.set_title(\"Brand Mentions by Category\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Add counts on top of bars\n",
    "for i, row in category_df.iterrows():\n",
    "    ax.text(i, row.frequency + 0.5, row.frequency, ha=\"center\")\n",
    "\n",
    "# SAVE VISUALIZATION\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"report/brand_category_mentions.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_df = pd.DataFrame.from_dict(counter, orient=\"index\", columns=[\"frequency\"])\n",
    "brand_df.frequency = brand_df.frequency.astype(int)\n",
    "\n",
    "\n",
    "@measure_time(\"plotting brands within category\")\n",
    "def plot_brand_data(\n",
    "    df: pd.DataFrame,\n",
    "    filter_condition: Union[List[bool], pd.Series],\n",
    "    label: str,\n",
    ") -> None:\n",
    "    \"\"\"Plots a horizontal bar chart of the counts in a dataframe, filtered by condition.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to plot data from.\n",
    "        filter_condition (Union[List[bool], pd.Series]): A boolean list or series used to filter the dataframe.\n",
    "        label (str): The label to use for the y-axis.\n",
    "    \"\"\"\n",
    "    # FILTER THE DATAFRAME BASED ON THE PROVIDED CONDITION\n",
    "    filtered_df = df.loc[filter_condition]\n",
    "\n",
    "    # SORT THE DATAFRAME BY COUNT\n",
    "    sorted_df = filtered_df.sort_values(\"frequency\", ascending=False)\n",
    "\n",
    "    # PLOT A HORIZONTAL BAR CHART\n",
    "    plt.figure(figsize=(10, len(sorted_df) * 0.5))\n",
    "    sns.barplot(x=\"frequency\", y=sorted_df.index, data=sorted_df, orient=\"h\")\n",
    "\n",
    "    # SET THE Y-AXIS LABEL\n",
    "    plt.ylabel(\"Brand\")\n",
    "    plt.title(f\"Brand Mentions by Category ({label})\")\n",
    "\n",
    "    # ADD COUNT TEXT TO THE RIGHT OF THE BARS\n",
    "    for i, v in enumerate(sorted_df.frequency):\n",
    "        plt.text(v + 1, i, str(v))\n",
    "\n",
    "    # SAVE VISUALIZATION\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"report/brand_data_{label}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# CALL FUNCTION FOR EACH CATEGORY\n",
    "plot_brand_data(brand_df, technology, \"Technology\")\n",
    "plot_brand_data(brand_df, clothing, \"Clothing\")\n",
    "plot_brand_data(brand_df, food, \"Food\")\n",
    "plot_brand_data(brand_df, entertainment, \"Entertainment\")\n",
    "plot_brand_data(brand_df, drinks, \"Drinks\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Tweets to Identify Brand Mentions\n",
    "\n",
    "We analyze tweets and identify mentions of specific brands. The process begins by standardizing the text in each tweet, which aids in detecting brand names. Each tweet is analyzed for brand mentions. When a brand is detected, we store the original tweet text, a flag indicating a brand mention, and the brand name itself. Where no brand is mentioned, we record the brand name as `nobrand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time(\"creating brands dataframe\")\n",
    "def create_brand_dataframe(tweets_df: pd.DataFrame, brands: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a new dataframe with brand labels.\n",
    "\n",
    "    Args:\n",
    "        tweets_df (pd.DataFrame): The dataframe containing tweets and sentiments.\n",
    "        brands (List[str]): The list of brands to be searched in the tweets.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The new dataframe with brand labels.\n",
    "    \"\"\"\n",
    "    brand_rows = []\n",
    "    non_brand_counter = 0\n",
    "    brand_counter = 0\n",
    "    for tweet, sentiment in zip(tweets_df.tweet, tweets_df.sentiment):\n",
    "        tweet_tokens = tweet.lower().split()\n",
    "        brand_found = False\n",
    "\n",
    "        for word in tweet_tokens:\n",
    "            word = word.replace(\"-\", \"\")\n",
    "            for brand in BRANDS:\n",
    "                if word == brand:\n",
    "                    brand_rows.append(\n",
    "                        {\"tweet\": tweet, \"brand\": brand, \"sentiment\": sentiment}\n",
    "                    )\n",
    "                    brand_found = True\n",
    "                    brand_counter += 1\n",
    "                    break\n",
    "\n",
    "            if brand_found:\n",
    "                break\n",
    "\n",
    "        if not brand_found and non_brand_counter < brand_counter:\n",
    "            brand_rows.append(\n",
    "                {\"tweet\": tweet, \"brand\": \"nobrand\", \"sentiment\": sentiment}\n",
    "            )\n",
    "            non_brand_counter += 1\n",
    "\n",
    "    brands_df = pd.DataFrame(brand_rows, columns=[\"tweet\", \"brand\", \"sentiment\"])\n",
    "    return brands_df\n",
    "\n",
    "\n",
    "brands_df = create_brand_dataframe(tweets_df, BRANDS)\n",
    "print(brands_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT DATASET TO FILE\n",
    "print(len(brands_df))\n",
    "brands_df.to_csv(\"datasets/brands.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation Using OpenAI's GPT-4 Model\n",
    "\n",
    "We define parameters for data generation using OpenAI's GPT-4 model. The parameters include the model name, the desired dataset size, and a user prompt that outlines the required data format.\n",
    "\n",
    "The data format is: \n",
    "\n",
    "\"tweet\"|||brand-presence|||brand\n",
    "\n",
    "Here, 'tweet' represents a Twitter post, 'brand-presence' is a binary indicator (0 or 1) denoting the presence or absence of a brand in the tweet, and 'brand' is the name of a brand from a predefined list or 'nobrand' when no brand is mentioned in the tweet.\n",
    "\n",
    "The user prompt also includes examples to guide the data generation process and specifies that the dataset should have an equal number of tweets with and without brand mentions.\n",
    "\n",
    "We use OpenAI's API to generate the data. The API key is retrieved from the environment variables, and a chat completion task is created using the GPT-4 model and the defined user prompt. The generated data is then extracted from the chat completion response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, brands, model=\"gpt-4\", samples_per_brand=100, cache_file=\"cache/generated_data.pkl\"):\n",
    "        self.brands = brands\n",
    "        self.model = model\n",
    "        self.samples_per_brand = samples_per_brand // 2  # Half for positive, half for negative\n",
    "        self.dataset_size = samples_per_brand * (len(brands) * 2 + 1)\n",
    "        self.dataset = []\n",
    "        self.seen_data = set()\n",
    "        self.brand_counts = {brand: 0 for brand in brands}\n",
    "        self.brand_counts['nobrand'] = 0\n",
    "        openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        self.cache_file = cache_file\n",
    "        self.load_or_initialize_dataset()\n",
    "\n",
    "    def load_or_initialize_dataset(self):\n",
    "        if os.path.exists(self.cache_file):\n",
    "            self.load_generated_data(self.cache_file)\n",
    "        else:\n",
    "            self.initialize_dataset()\n",
    "\n",
    "    def initialize_dataset(self):\n",
    "        self.dataset = []\n",
    "        self.seen_data = set()\n",
    "        self.brand_counts = {brand: 0 for brand in self.brands}\n",
    "        self.brand_counts['nobrand'] = 0\n",
    "\n",
    "    def generate_data(self, user_prompt):\n",
    "        wait_time = 5\n",
    "        while True:\n",
    "            try:\n",
    "                chat_completion = openai.ChatCompletion.create(\n",
    "                    model=self.model,\n",
    "                    temperature=0.4,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": user_prompt},\n",
    "                    ],\n",
    "                )\n",
    "                break\n",
    "            except openai.OpenAIError as e:\n",
    "                if 'Rate limit exceeded' in str(e):\n",
    "                    print(f'Rate limit exceeded. Waiting for {wait_time} seconds...')\n",
    "                    time.sleep(wait_time)\n",
    "                    wait_time *= 2  # Increase wait time\n",
    "                else:\n",
    "                    raise e\n",
    "        raw_chat_completion = chat_completion.choices[0].message.content\n",
    "        return raw_chat_completion\n",
    "\n",
    "    def generate_nobrand_data(self, batch_size):\n",
    "        user_prompt = self.create_nobrand_prompt(batch_size)\n",
    "        self.generate_and_add_data(user_prompt, 'nobrand', batch_size)\n",
    "\n",
    "    def create_nobrand_prompt(self, batch_size):\n",
    "        return f\"\"\"\n",
    "            Create some data in the format: \n",
    "\n",
    "            \"tweet\"|||brand\n",
    "\n",
    "            where:\n",
    "                tweet is a Twitter post, \n",
    "                brand is 'nobrand' when no brand is present.\n",
    "\n",
    "            EXAMPLES:\n",
    "                \"@john Just finished a great workout!\"|||nobrand\n",
    "                \"The weather is beautiful today.\"|||nobrand\n",
    "                \"@mary Reading a good book is the best way to relax.\"|||nobrand\n",
    "                \"I ate some grapes yesterday and I loved them.\"|||nobrand\n",
    "\n",
    "            Create {batch_size} data points.\n",
    "            \"\"\"\n",
    "\n",
    "    def generate_brand_positive_data(self, brand, batch_size):\n",
    "        user_prompt = self.create_brand_positive_prompt(brand, batch_size)\n",
    "        self.generate_and_add_data(user_prompt, brand, batch_size, 1)\n",
    "\n",
    "    def create_brand_positive_prompt(self, brand, batch_size):\n",
    "        return f\"\"\"\n",
    "            Create some data in the format: \n",
    "\n",
    "            \"tweet\"|||brand|||sentiment \n",
    "\n",
    "            where:\n",
    "                tweet is a Twitter post, \n",
    "                brand is {brand}, and\n",
    "                sentiment is 1 indicating positive sentiment of the tweet.\n",
    "\n",
    "            EXAMPLES:\n",
    "                \"@mike {brand} is the best!\"|||{brand}|||1\n",
    "                \"Just tried {brand} for the first time, it's amazing!\"|||{brand}|||1\n",
    "                \"@lisa My experience with {brand} was excellent!\"|||{brand}|||1\n",
    "                \"I love {brand}!\"|||{brand}|||1\n",
    "\n",
    "            Create {batch_size} data points.\n",
    "            \"\"\"\n",
    "\n",
    "    def generate_brand_negative_data(self, brand, batch_size):\n",
    "        user_prompt = self.create_brand_negative_prompt(brand, batch_size)\n",
    "        self.generate_and_add_data(user_prompt, brand, batch_size, 0)\n",
    "\n",
    "    def create_brand_negative_prompt(self, brand, batch_size):\n",
    "        return f\"\"\"\n",
    "            Create some data in the format: \n",
    "\n",
    "            \"tweet\"|||brand|||sentiment \n",
    "\n",
    "            where:\n",
    "                tweet is a Twitter post, \n",
    "                brand is {brand}, and\n",
    "                sentiment is 0 indicating negative sentiment of the tweet.\n",
    "\n",
    "            EXAMPLES:\n",
    "                \"@ashman01 My only complaint about {brand} is that it's not what it used to be.\"|||{brand}|||0\n",
    "                \"I'm really disappointed with {brand}.\"|||{brand}|||0\n",
    "                \"@jane The quality of {brand} has gone down.\"|||{brand}|||0\n",
    "                \"My experience with {brand} was not good.\"|||{brand}|||0\n",
    "\n",
    "            Create {batch_size} data points.\n",
    "            \"\"\"\n",
    "\n",
    "    def generate_and_add_data(self, user_prompt, brand, batch_size, sentiment=None, max_retries=3):\n",
    "        if self.brand_counts[brand] >= self.samples_per_brand:\n",
    "            raise ValueError(f\"Maximum number of samples for {brand} already reached.\")\n",
    "        \n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            data = self.generate_data(user_prompt)\n",
    "            data = data.split('\\n')\n",
    "            valid_data = [item for item in data if len(item.split('|||')) >= 2]\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                for item in valid_data:\n",
    "                    if len(self.dataset) >= self.dataset_size:\n",
    "                        break\n",
    "                    if item not in self.seen_data:\n",
    "                        self.dataset.append(item)\n",
    "                        self.seen_data.add(item)\n",
    "                        self.brand_counts[brand] += 1\n",
    "                break\n",
    "            else:\n",
    "                retries += 1\n",
    "\n",
    "        if retries == max_retries:\n",
    "            print(f\"Failed to generate valid data for {brand} after {max_retries} attempts.\")\n",
    "            \n",
    "    def generate_balanced_dataset(self):\n",
    "        brand_index = 0\n",
    "        sentiment = 0\n",
    "        batch_size = 50 \n",
    "        progress_bars = {brand: tqdm(total=self.samples_per_brand, desc=brand, position=i, leave=True) \n",
    "                        for i, brand in enumerate(self.brands + ['nobrand'])}\n",
    "        while len(self.dataset) < self.dataset_size:\n",
    "            if brand_index < len(self.brands):\n",
    "                brand = self.brands[brand_index]\n",
    "                if self.brand_counts[brand] < self.samples_per_brand:\n",
    "                    if sentiment == 0:\n",
    "                        progress_bars[brand].set_description(Fore.YELLOW + f\"Generating negative data for {brand}\" + Style.RESET_ALL)\n",
    "                        self.generate_brand_negative_data(brand, batch_size)\n",
    "                    else:\n",
    "                        progress_bars[brand].set_description(Fore.GREEN + f\"Generating positive data for {brand}\" + Style.RESET_ALL)\n",
    "                        self.generate_brand_positive_data(brand, batch_size)\n",
    "                    progress_bars[brand].update(self.brand_counts[brand] - progress_bars[brand].n)\n",
    "                else:\n",
    "                    progress_bars[brand].set_description(Fore.RED + f\"Skipping {brand} (already reached maximum samples)\" + Style.RESET_ALL)\n",
    "                brand_index = (brand_index + 1) % (len(self.brands) + 1)\n",
    "                sentiment = (sentiment + 1) % 2\n",
    "                self.save_generated_data()  # Save after each batch\n",
    "                self.report_metrics()  # Report metrics after each batch\n",
    "            else:\n",
    "                if self.brand_counts['nobrand'] < self.samples_per_brand * len(self.brands):\n",
    "                    progress_bars['nobrand'].set_description(Fore.BLUE + \"Generating nobrand data\" + Style.RESET_ALL)\n",
    "                    self.generate_nobrand_data(batch_size)\n",
    "                    progress_bars['nobrand'].update(self.brand_counts['nobrand'] - progress_bars['nobrand'].n)\n",
    "                else:\n",
    "                    progress_bars['nobrand'].set_description(Fore.RED + \"Skipping nobrand (already reached maximum samples)\" + Style.RESET_ALL)\n",
    "                brand_index = (brand_index + 1) % (len(self.brands) + 1)\n",
    "        for pbar in progress_bars.values():\n",
    "            pbar.close()\n",
    "        print(\"Data generation completed!\")\n",
    "        self.report_metrics()  # Report final metrics\n",
    "\n",
    "        while not self.is_balanced():\n",
    "            for brand in self.brands:\n",
    "                while self.brand_counts[brand] < self.samples_per_brand:\n",
    "                    if sentiment == 0:\n",
    "                        self.generate_brand_negative_data(brand, 1)\n",
    "                    else:\n",
    "                        self.generate_brand_positive_data(brand, 1)\n",
    "                    sentiment = (sentiment + 1) % 2\n",
    "                while self.brand_counts[brand] > self.samples_per_brand:\n",
    "                    self.delete_extra_data(brand)\n",
    "\n",
    "    def delete_extra_data(self, brand):\n",
    "        for i in reversed(range(len(self.dataset))):\n",
    "            data = self.dataset[i]\n",
    "            if data.split('|||')[1] == brand:\n",
    "                del self.dataset[i]\n",
    "                self.brand_counts[brand] -= 1\n",
    "                break\n",
    "\n",
    "    def save_generated_data(self):\n",
    "        with open(self.cache_file, \"wb\") as f:\n",
    "            pickle.dump(self.dataset, f)\n",
    "\n",
    "    def load_generated_data(self, filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            loaded_data = pickle.load(f)\n",
    "        if isinstance(loaded_data, list):\n",
    "            self.dataset = loaded_data\n",
    "            self.update_counts()\n",
    "        else:\n",
    "            print(\"Loaded data is not in the expected format (list), initializing a new dataset.\")\n",
    "            self.initialize_dataset()\n",
    "\n",
    "    def update_counts(self):\n",
    "        for data in self.dataset:\n",
    "            parts = data.split(\"|||\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            brand = parts[1] \n",
    "            self.brand_counts[brand] += 1\n",
    "\n",
    "    def is_balanced(self):\n",
    "        brand_counts = list(self.brand_counts.values())\n",
    "        return max(brand_counts) - min(brand_counts) <= 1\n",
    "\n",
    "    def balance_dataset(self):\n",
    "        while not self.is_balanced():\n",
    "            self.generate_balanced_dataset()\n",
    "\n",
    "    def check_and_report_balance(self):\n",
    "        if self.is_balanced():\n",
    "            print(\"The dataset is balanced.\")\n",
    "        else:\n",
    "            print(\"The dataset is not balanced.\")\n",
    "        self.report_metrics()\n",
    "\n",
    "    def report_metrics(self):\n",
    "        print(\"Brand Counts:\")\n",
    "        for brand, count in self.brand_counts.items():\n",
    "            print(f\"{brand}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m data_generator \u001b[39m=\u001b[39m DataGenerator(BRANDS)\n\u001b[1;32m      3\u001b[0m \u001b[39m# GENERATE BALANCED DATASET\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data_generator\u001b[39m.\u001b[39;49mgenerate_balanced_dataset()\n\u001b[1;32m      6\u001b[0m \u001b[39m# CHECK AND REPORT BALANCE\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data_generator\u001b[39m.\u001b[39mcheck_and_report_balance()\n",
      "Cell \u001b[0;32mIn[150], line 157\u001b[0m, in \u001b[0;36mDataGenerator.generate_balanced_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m sentiment \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    156\u001b[0m     progress_bars[brand]\u001b[39m.\u001b[39mset_description(Fore\u001b[39m.\u001b[39mYELLOW \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating negative data for \u001b[39m\u001b[39m{\u001b[39;00mbrand\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m Style\u001b[39m.\u001b[39mRESET_ALL)\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_brand_negative_data(brand, batch_size)\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     progress_bars[brand]\u001b[39m.\u001b[39mset_description(Fore\u001b[39m.\u001b[39mGREEN \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerating positive data for \u001b[39m\u001b[39m{\u001b[39;00mbrand\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m Style\u001b[39m.\u001b[39mRESET_ALL)\n",
      "Cell \u001b[0;32mIn[150], line 98\u001b[0m, in \u001b[0;36mDataGenerator.generate_brand_negative_data\u001b[0;34m(self, brand, batch_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_brand_negative_data\u001b[39m(\u001b[39mself\u001b[39m, brand, batch_size):\n\u001b[1;32m     97\u001b[0m     user_prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_brand_negative_prompt(brand, batch_size)\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_and_add_data(user_prompt, brand, batch_size, \u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[150], line 126\u001b[0m, in \u001b[0;36mDataGenerator.generate_and_add_data\u001b[0;34m(self, user_prompt, brand, batch_size, sentiment, max_retries)\u001b[0m\n\u001b[1;32m    124\u001b[0m retries \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[39mwhile\u001b[39;00m retries \u001b[39m<\u001b[39m max_retries:\n\u001b[0;32m--> 126\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_data(user_prompt)\n\u001b[1;32m    127\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    128\u001b[0m     valid_data \u001b[39m=\u001b[39m [item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(item\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m|||\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m]\n",
      "Cell \u001b[0;32mIn[150], line 31\u001b[0m, in \u001b[0;36mDataGenerator.generate_data\u001b[0;34m(self, user_prompt)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m         chat_completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     32\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m     33\u001b[0m             temperature\u001b[39m=\u001b[39;49m\u001b[39m0.4\u001b[39;49m,\n\u001b[1;32m     34\u001b[0m             messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     35\u001b[0m                 {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_prompt},\n\u001b[1;32m     36\u001b[0m             ],\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[39mexcept\u001b[39;00m openai\u001b[39m.\u001b[39mOpenAIError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/venv/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_generator = DataGenerator(BRANDS)\n",
    "\n",
    "# GENERATE BALANCED DATASET\n",
    "data_generator.generate_balanced_dataset()\n",
    "\n",
    "# CHECK AND REPORT BALANCE\n",
    "data_generator.check_and_report_balance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_chat_completion))\n",
    "raw_chat_completion += \"\\n\"\n",
    "raw_chat_completion += generate_data(USER_PROMPT_BRANDS_ONLY)\n",
    "print(json.dumps(raw_chat_completion.split(\"\\n\"), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_chat_completion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Integrating Generated Data\n",
    "\n",
    "The raw content generated by the GPT-4 model is processed by splitting it into three parts: 'tweet', 'brand-presence', and 'brand'. This is achieved by separating each line of the raw content on the delimiter '|||'. The processed content is then stored in a structured format as a list of dictionaries.\n",
    "\n",
    "The processed content is converted into a pandas DataFrame and added to the existing `brands_df` DataFrame. This integration step ensures the newly generated data is combined with any current data for further analysis. Any missing values in the 'brand' column of the DataFrame are filled with 'nobrand'. This step ensures data consistency by providing a placeholder value for tweets where no brand is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT RAW CONTENT INTO tweet, brand-presence, AND brand\n",
    "raw_content = raw_chat_completion.split(\"\\n\")\n",
    "processed_content = [s.split(\"|||\") for s in raw_content]\n",
    "\n",
    "# CONVERT TO DATAFRAME\n",
    "processed_content_df = pd.DataFrame(\n",
    "    processed_content, columns=[\"tweet\", \"brand\", \"sentiment\"]\n",
    ")\n",
    "\n",
    "# MERGE processed_content_df INTO brands_df\n",
    "brands_df = pd.concat([brands_df, processed_content_df], ignore_index=True)\n",
    "\n",
    "# PRINT PROCESSED CONTENT\n",
    "print(json.dumps(processed_content, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"brands_df.shape: {brands_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"brands_df.brand.value_counts(): {brands_df.brand.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"brands_df.tail(6): \\n{brands_df.tail(6)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand Mention Distribution Visualization\n",
    "\n",
    "We create a visual representation of the distribution of brand mentions within a collection of tweets. We use a bar plot to illustrate the count of tweets mentioning a brand versus those not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_presence = brands_df[\"brand\"].apply(\n",
    "    lambda x: \"No Brand\" if x == \"nobrand\" else \"Brand\"\n",
    ")\n",
    "print(brand_presence.value_counts())\n",
    "\n",
    "counts = brand_presence.value_counts().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = sns.barplot(x=\"index\", y=brand_presence.name, data=counts)\n",
    "plt.title(\"Presence of Brand in Tweets\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    # ADD COUNTS TO BARS\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2.0,\n",
    "        p.get_height(),\n",
    "        \"%d\" % int(p.get_height()),\n",
    "        fontsize=12,\n",
    "        color=\"black\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "# SAVE VISUALIZATION\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"report/brand_count.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = brands_df[\"brand\"].value_counts()\n",
    "print(brand_counts)\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.pie(\n",
    "    brand_counts,\n",
    "    labels=brand_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=140,\n",
    "    pctdistance=0.85,\n",
    "    labeldistance=1,\n",
    ")\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Proportion of Tweets Referencing Each Brand\")\n",
    "\n",
    "# SAVE VISUALIZATION\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"report/proportion_brands_in_tweets.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Toolkit (`nltk`) for Text Processing\n",
    "\n",
    "We initialize the Natural Language Toolkit (`nltk`), a Python library for processing human language data. It offers tools for various tasks, including classification, tokenization, stemming, tagging, parsing, and semantic reasoning.\n",
    "\n",
    "Key parts from `nltk` are downloaded: a tokenizer, a part-of-speech tagger, a named entity chunker, a corpus of words, a multilingual lexical database, and a corpus of stopwords. \n",
    "\n",
    "The tokenizer helps break down the text into sentences or words, the part-of-speech tagger assigns parts of speech to individual words, and the named entity chunker identifies named entities within the text.\n",
    "\n",
    "The corpus of words and the multilingual lexical database can be used for tasks such as spellchecking or language identification.\n",
    "\n",
    "The stopwords corpus lists common words, known as \"stop words\", in several languages, including English. These words are often filtered out during text processing and rarely have significant meaning.\n",
    "\n",
    "We generate a set of English stop words to expedite membership checking. This set will be used later in the text processing pipeline to filter out stop words from the text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUNKT TOKENIZER FOR SENTENCE TOKENIZATION\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# TAGGER FOR PART-OF-SPEECH TAGGING\n",
    "nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "\n",
    "# CHUNKER FOR NAMED ENTITY RECOGNITION\n",
    "nltk.download(\"maxent_ne_chunker\", quiet=True)\n",
    "\n",
    "# CORPUS OF WORDS FOR SPELLCHECKING OR LANGUAGE IDENTIFICATION\n",
    "nltk.download(\"words\", quiet=True)\n",
    "\n",
    "# MULTILINGUAL LEXICAL DATABASE\n",
    "nltk.download(\"omw-1.4\", quiet=True)\n",
    "\n",
    "# DOWNLOAD STOPWORDS CORPUS\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "# CREATE SET OF ENGLISH STOPWORDS FOR FASTER MEMBERSHIP CHECKING\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Tweets for Text Analysis\n",
    "\n",
    "We implement a preprocessing function to clean and standardize the text in tweets. This function removes URLs and @mentions, tokenizes the text into individual words, removes stopwords and punctuation, and applies stemming to reduce words to their root form. This preprocessing function is then applied to each tweet in the dataset. A sample of the original and preprocessed tweets is displayed to visually check the preprocessing results. This step ensures the preprocessing function works as expected and the tweets are ready for further text analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET OPTIONS TO REMOVE URLS AND @MENTIONS\n",
    "preprocessor.set_options(preprocessor.OPT.URL, preprocessor.OPT.MENTION)\n",
    "\n",
    "# INITIALIZE STEMMER\n",
    "STEMMER = SnowballStemmer(\"english\")\n",
    "\n",
    "# CONVERT STOPWORDS AND PUNCTUATION TO SETS\n",
    "STOP_WORDS_SET = set(STOP_WORDS)\n",
    "PUNCTUATION_SET = set(string.punctuation)\n",
    "\n",
    "\n",
    "def preprocess(tweet: str) -> list:\n",
    "    \"\"\"\n",
    "    Function to preprocess a tweet by removing URLs, @mentions, stopwords and punctuation.\n",
    "    It also tokenizes and stems the tweet.\n",
    "\n",
    "    Args:\n",
    "        tweet (str): The tweet to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "        list: The preprocessed tweet as a list of stemmed tokens.\n",
    "    \"\"\"\n",
    "    # CLEAN TWEET BY REMOVING URLS AND @MENTIONS\n",
    "    cleaned = preprocessor.clean(tweet)\n",
    "    # TOKENIZE TWEET INTO INDIVIDUAL WORDS\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", cleaned)\n",
    "    # REMOVE STOPWORDS AND PUNCTUATION FROM TOKENS\n",
    "    filtered = [\n",
    "        word\n",
    "        for word in tokens\n",
    "        if word not in STOP_WORDS_SET and word not in PUNCTUATION_SET\n",
    "    ]\n",
    "    # APPLY STEMMING TO FILTERED TOKENS\n",
    "    stemmed = [STEMMER.stem(word) for word in filtered]\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "@measure_time(\"preprocessing training data\")\n",
    "def apply_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Function to apply preprocessing to each tweet in the DataFrame using multithreading.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing the tweets.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with the preprocessed tweets.\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        df[\"processed_text\"] = list(executor.map(preprocess, df.tweet))\n",
    "    return df\n",
    "\n",
    "\n",
    "@measure_time(\"saving preprocessed data\")\n",
    "def save_preprocessed(df, filename):\n",
    "    \"\"\"\n",
    "    Function to save preprocessed DataFrame to a file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to be saved.\n",
    "        filename (str): The name of the file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "\n",
    "@measure_time(\"loading preprocessed data\")\n",
    "def load_preprocessed(filename):\n",
    "    \"\"\"\n",
    "    Function to load preprocessed DataFrame from a file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# LOAD FROM FILE IF EXISTS (DELETE FILE TO RE-PREPROCESS)\n",
    "preprocessed_file = \"cache/preprocessed_train.pkl\"\n",
    "if os.path.exists(preprocessed_file):\n",
    "    tweets_df = load_preprocessed(preprocessed_file)\n",
    "else:\n",
    "    # USE MULTITHREADING TO APPLY PREPROCESSING\n",
    "    tweets_df = apply_preprocessing(tweets_df)\n",
    "    save_preprocessed(tweets_df, preprocessed_file)\n",
    "\n",
    "# SHOW SAMPLE PROCESSED TWEETS\n",
    "tweets_sample = tweets_df[tweets_df.sentiment == 1].head()\n",
    "for index, row in tweets_sample.iterrows():\n",
    "    print(f\"ORIGINAL: {row.tweet}\")\n",
    "    print(f\"PROCESSED: {row.processed_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW FIRST FEW ROWS OF PREPROCESSED TRAINING DATA\n",
    "print(\"\\n\".join([str(text) for text in tweets_df.processed_text.head()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time(\"getting word sentiment frequencies\")\n",
    "def get_word_sentiment_frequencies(df):\n",
    "    \"\"\"\n",
    "    Get word-sentiment frequencies from a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the tweets and sentiment labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with word-sentiment pairs as keys and their frequencies as values.\n",
    "    \"\"\"\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(df.sentiment.values.tolist(), df.processed_text):\n",
    "        for word in tweet:\n",
    "            pair = (word, y)\n",
    "            freqs[pair] = freqs.get(pair, 0) + 1\n",
    "\n",
    "    freqs_sorted = dict(sorted(freqs.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return freqs_sorted\n",
    "\n",
    "\n",
    "freqs_sorted = get_word_sentiment_frequencies(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NUMBER OF UNIQUE WORD-SENTIMENT PAIRS: {len(freqs_sorted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time(\"printing sample preprocessed text\")\n",
    "def print_around_average(freqs_sorted: Dict[Tuple[Any, int], int]) -> None:\n",
    "    \"\"\"\n",
    "    Print the first 5 items, 5 items around the average frequency, and last 5 items in a sorted dictionary.\n",
    "\n",
    "    Args:\n",
    "        freqs_sorted (dict): The sorted dictionary.\n",
    "    \"\"\"\n",
    "    # PRINT FIRST 5 ITEMS IN THE SORTED DICTIONARY\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in itertools.islice(freqs_sorted.items(), 5)))\n",
    "\n",
    "    # PRINT 5 ITEMS AROUND THE AVERAGE FREQUENCY\n",
    "    # Calculate the average frequency\n",
    "    avg_freq = sum(freqs_sorted.values()) / len(freqs_sorted)\n",
    "\n",
    "    # Find the index of the first item with a frequency just below the average\n",
    "    below_avg_index = next(\n",
    "        i for i, v in enumerate(freqs_sorted.values()) if v < avg_freq\n",
    "    )\n",
    "\n",
    "    # Get 5 items around the average frequency\n",
    "    start_index = below_avg_index - 2  # 2 items before the average\n",
    "    end_index = below_avg_index + 3  # 2 items after the average\n",
    "\n",
    "    # Convert dictionary items to a list and slice the 5 items around the average\n",
    "    around_avg_items = list(freqs_sorted.items())[start_index:end_index]\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in around_avg_items))\n",
    "\n",
    "    # PRINT LAST 5 ITEMS IN THE SORTED DICTIONARY\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in list(freqs_sorted.items())[-5:]))\n",
    "\n",
    "\n",
    "print_around_average(freqs_sorted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Sentiment Distribution for Frequently Occurring Word Stems\n",
    "\n",
    "We create a scatter plot to analyze our dataset's 50 most often occurring word stems. Each point on the plot corresponds to a word stem, positioned according to its occurrence in positive and negative sentiments.\n",
    "\n",
    "Handling large frequency counts can lead to complexity in graphical representation. To tackle this, we apply a logarithmic transformation to the data. This technique simplifies the visualization of large numbers, making the information easier to understand. Each point on the graph is labeled with the word stem it represents. Additionally, a line is drawn on the plot to represent an equal frequency of positive and negative sentiments. This element aids in quickly determining whether a word stem is primarily associated with positive or negative sentiments in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time(\"generating sentiment counts plot\")\n",
    "def generate_sentiment_counts_plot(freqs_sorted, n=50):\n",
    "    # GET UNIQUE LIST OF WORDS FROM KEYS IN FREQS_SORTED\n",
    "    word_list = list(set(word for word, sentiment in freqs_sorted.keys()))\n",
    "\n",
    "    # BUILD LIST OF WORDS WITH POSITIVE AND NEGATIVE SENTIMENT COUNTS\n",
    "    data = [\n",
    "        [word, freqs_sorted.get((word, 1), 0), freqs_sorted.get((word, 0), 0)]\n",
    "        for word in word_list\n",
    "        # Remove i since it is an outlier\n",
    "        if word != \"i\"\n",
    "    ]\n",
    "\n",
    "    # SORT DATA BY THE SUM OF POSITIVE AND NEGATIVE COUNTS AND LIMIT TO TOP 'n' MOST FREQUENT WORDS\n",
    "    data = sorted(data, key=lambda x: x[1] + x[2], reverse=True)[:n]\n",
    "\n",
    "    # PREPARE X AND Y FOR PLOT, APPLY LOG TRANSFORMATION FOR LARGE COUNTS\n",
    "    x = np.log([x[1] + 1 for x in data])\n",
    "    y = np.log([x[2] + 1 for x in data])\n",
    "\n",
    "    # CREATE SCATTER PLOT FOR LOG-TRANSFORMED COUNTS\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.title(f\"Positive and Negative Counts of {n} Most Frequent Word Stems\")\n",
    "    plt.xlabel(\"Log Positive count\")\n",
    "    plt.ylabel(\"Log Negative count\")\n",
    "\n",
    "    # ADD ANNOTATIONS TO EACH POINT IN SCATTER PLOT, ADJUST TO AVOID OVERLAP\n",
    "    texts = []\n",
    "    for i in range(len(data)):\n",
    "        texts.append(plt.text(x[i], y[i], data[i][0], fontsize=12))\n",
    "\n",
    "    adjust_text(texts)\n",
    "\n",
    "    # ADD RED LINE FROM MINIMUM TO MAXIMUM VALUE ON BOTH AXES\n",
    "    min_val = min(np.min(x), np.min(y))\n",
    "    max_val = max(np.max(x), np.max(y))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color=\"red\")\n",
    "\n",
    "    # SAVE VISUALIZATION\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"report/positive_and_negative_counts.png\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the function\n",
    "generate_sentiment_counts_plot(freqs_sorted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Evaluate Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights & Biases (`wandb`) Setup\n",
    "\n",
    "We use Weights & Biases (wandb) for experiment tracking. This MLOps tool allows us to compare metrics from different runs and visualize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand Classifer\n",
    "\n",
    "The `BrandClassifier` class is a comprehensive tool created to identify brand mentions in tweets. It operates with a specified machine-learning model and a vectorizer responsible for transforming text data into a numerical format that the model can process. Once configured, the `BrandClassifier` can train the model with given data, predict based on new data inputs, and evaluate the accuracy of the model's performance. The class structures data into training, testing, and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrandClassifier:\n",
    "    \"\"\"A generic brand classifier.\"\"\"\n",
    "\n",
    "    @measure_time(\"initializing classifier\")\n",
    "    def __init__(\n",
    "        self, classifier, vectorizer: CountVectorizer = CountVectorizer()\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the classifier with a vectorizer and classifier.\n",
    "\n",
    "        Args:\n",
    "            classifier: The classifier to use.\n",
    "            vectorizer: The vectorizer to use. Defaults to CountVectorizer().\n",
    "        \"\"\"\n",
    "        self.model = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", classifier)])\n",
    "        datetime_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        classifier_name = self.model.named_steps[\"classifier\"].__class__.__name__\n",
    "        wandb.init(\n",
    "            project=\"brand-sentiment-analysis\",\n",
    "            name=f\"{datetime_stamp}-{classifier_name}\",\n",
    "        )\n",
    "\n",
    "    @measure_time(\"training classifier\")\n",
    "    def fit(self, X_train: List[str], y_train: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Fits the model to the training data.\n",
    "\n",
    "        Args:\n",
    "            X_train: The training data.\n",
    "            y_train: The training labels.\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    @measure_time(\"predicting sentiment\")\n",
    "    def predict(self, X: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Predicts the labels for the given data.\n",
    "\n",
    "        Args:\n",
    "            X: The data to predict labels for.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: The predicted labels.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    @measure_time(\"evaluating classifier\")\n",
    "    def evaluate(self, X: List[str], y: List[str]) -> Tuple[float, float, float, float]:\n",
    "        \"\"\"\n",
    "        Evaluates the model on the given data and returns the accuracy, precision, recall, and F1 score.\n",
    "\n",
    "        Args:\n",
    "            X: The data to evaluate the model on.\n",
    "            y: The true labels for the data.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, float, float, float]: The accuracy, precision, recall, and F1 score.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        precision = precision_score(y, y_pred)\n",
    "        recall = recall_score(y, y_pred)\n",
    "        f1 = f1_score(y, y_pred)\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    @measure_time(\"printing classifier results\")\n",
    "    def print_scores(\n",
    "        self, scores: Tuple[float, float, float, float], data_name: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Prints the accuracy, precision, recall, and F1 score.\n",
    "\n",
    "        Args:\n",
    "            scores: The scores to print.\n",
    "            data_name: The name of the data the scores are for.\n",
    "        \"\"\"\n",
    "        accuracy, precision, recall, f1 = scores\n",
    "        print(f\"{data_name} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"{data_name} Precision: {precision:.4f}\")\n",
    "        print(f\"{data_name} Recall: {recall:.4f}\")\n",
    "        print(f\"{data_name} F1: {f1:.4f}\")\n",
    "\n",
    "    @measure_time(\"finishing run\")\n",
    "    def finish(self, scores: Tuple[float, float, float, float]) -> None:\n",
    "        \"\"\"\n",
    "        Finishes the wandb run and saves the trained model as an artifact.\n",
    "\n",
    "        Args:\n",
    "            scores: The scores of the model.\n",
    "        \"\"\"\n",
    "        # INITIALIZE NEW ARTIFACT\n",
    "        classifier_name = self.model.named_steps[\"classifier\"].__class__.__name__\n",
    "        accuracy, precision, recall, f1 = scores\n",
    "\n",
    "        artifact = wandb.Artifact(\n",
    "            classifier_name,\n",
    "            type=\"model\",\n",
    "            description=\"Trained model for brand sentiment analysis\",\n",
    "            metadata={\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # ADD MODEL TO ARTIFACT\n",
    "        joblib.dump(self.model, \"model.pkl\")\n",
    "        artifact.add_file(\"model.pkl\", name=\"classifier_name\")\n",
    "\n",
    "        # LOG ARTIFACT TO wandb\n",
    "        wandb.log_artifact(artifact)\n",
    "\n",
    "        # DELETE TEMPORARY ARTIFACT FROM FILESYSTEM\n",
    "        os.remove(\"model.pkl\")\n",
    "\n",
    "        # FINISH RUN\n",
    "        wandb.finish()\n",
    "\n",
    "    @measure_time(\"splitting data\")\n",
    "    def split_data(\n",
    "        self, X: List[str], y: List[str]\n",
    "    ) -> Tuple[List[str], List[str], List[str], List[str], List[str], List[str]]:\n",
    "        \"\"\"\n",
    "        Splits the data into training, test, validation sets.\n",
    "\n",
    "        Args:\n",
    "            X: The data to split.\n",
    "            y: The labels to split.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[str], List[str], List[str], List[str], List[str], List[str]]: The train, test, validate data and labels.\n",
    "        \"\"\"\n",
    "        # SPLIT DATA INTO TRAINING SET AND TEMP SET WITH 80/20 SPLIT\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # SPLIT TEMP SET INTO VALIDATION SET AND TEST SET WITH 50/50 SPLIT\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=42\n",
    "        )\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "\n",
    "    @measure_time(\"running classifier\")\n",
    "    def run(self, X: List[str], y: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Runs the entire process from training to testing.\n",
    "\n",
    "        Args:\n",
    "            X: The data to use.\n",
    "            y: The labels to use.\n",
    "        \"\"\"\n",
    "        # SPLIT DATA\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = self.split_data(X, y)\n",
    "\n",
    "        # FIT MODEL\n",
    "        self.fit(X_train, y_train)\n",
    "\n",
    "        # EVALUATE MODEL ON VALIDATION SET\n",
    "        val_scores = self.evaluate(X_val, y_val)\n",
    "        self.print_scores(val_scores, \"Validation\")\n",
    "\n",
    "        # EVALUATE MODEL ON TEST SET\n",
    "        test_scores = self.evaluate(X_test, y_test)\n",
    "        self.print_scores(test_scores, \"Test\")\n",
    "\n",
    "        # FINISH RUN\n",
    "        self.finish(test_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes (`MultinomialNB`)\n",
    "\n",
    "The Multinomial Naive Bayes classifier is a widely recognized and used tool in text classification. This classifier is based on Bayes' theorem, a principle in probability theory and statistics that describes the probability of an event based on prior knowledge of conditions that might be related to the event. The Multinomial Naive Bayes classifier assumes that all features, such as words in a tweet, are independent of each other. This is often called the 'naive' assumption, hence the name Naive Bayes.\n",
    "\n",
    "This classifier is effective when dealing with features that are discrete counts. In text classification, this could be the number of times a specific word appears in a document or a tweet. The Multinomial Naive Bayes classifier requires these counts to be integers, aligning perfectly with word counts in text data. This makes the Multinomial Naive Bayes classifier an ideal choice for our text classification needs, as it can effectively handle and make predictions based on the vectorized text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrandClassifier(MultinomialNB()).run(brands_df.tweet, brands_df.brand_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand classification using Multinomial Naive Bayes using brand (name) as the target\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(brands_df.tweet)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(brands_df.brand)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2)\n",
    "model = MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "predictions = model.predict(xtest)\n",
    "predicted_brand_names = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "accuracy = accuracy_score(ytest, predictions)\n",
    "precision_micro = precision_score(ytest, predictions, average=\"micro\")\n",
    "precision_macro = precision_score(ytest, predictions, average=\"macro\")\n",
    "precision_weighted = precision_score(ytest, predictions, average=\"weighted\")\n",
    "# recall = recall_score(ytest, predictions)\n",
    "# f1 = f1_score(ytest, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (micro average): {precision_micro:.4f}\")\n",
    "print(f\"Precision (macro average): {precision_macro:.4f}\")\n",
    "print(f\"Precision (weighted average): {precision_weighted:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1: {f1:.4f}\")\n",
    "\n",
    "class_labels = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n",
    "print(class_labels)\n",
    "cm = confusion_matrix(ytest, predictions)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    cm, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Quick test\n",
    "new_tweets = [\n",
    "    \"apple is the best company\",\n",
    "    \"I love apples\",\n",
    "    \"Apples are the worst\",\n",
    "    \"I like apple?\",\n",
    "]\n",
    "\n",
    "new_tweets_vectorized = vectorizer.transform(new_tweets)\n",
    "\n",
    "# Predict the class using the trained model\n",
    "test_prediction = model.predict(new_tweets_vectorized)\n",
    "\n",
    "# If needed, inverse transform the predicted label to get the brand name\n",
    "new_predicted_brand_name = label_encoder.inverse_transform(test_prediction)\n",
    "\n",
    "print(new_predicted_brand_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classifier (`LinearSVC`)\n",
    "\n",
    "The Linear Support Vector Classifier is a Support Vector Machine (SVM) often used for text classification tasks. SVMs are supervised learning methods for classification, regression, and outliers detection. The LinearSVC works by identifying the best boundary or 'hyperplane' that separates different data classes. This is achieved by maximizing the margin between the classes in the training data.\n",
    "\n",
    "One of the strengths of LinearSVC is its ability to handle high-dimensional data. In text classification, once the text data is vectorized, it can result in a high-dimensional feature space, where each dimension corresponds to a unique word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrandClassifier(LinearSVC()).run(brands_df.tweet, brands_df.brand_presence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic Regression is a statistical model used to predict the probability of a specific class or event. Despite its name, Logistic Regression is used for classification tasks, not regression tasks. In text classification, it's used to predict the likelihood of a specific word belonging to a particular category or class, such as whether a tweet mentions a brand.\n",
    "\n",
    "Logistic Regression is known for its simplicity and efficiency. It uses a logistic function to model a binary dependent variable, making it a suitable choice for tasks where the output can be one of two possible outcomes. In our case, this could be whether a tweet mentions a brand or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BrandClassifier(LogisticRegression()).run(brands_df.tweet, brands_df.brand_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT METRICS\n",
    "metrics.print_metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
