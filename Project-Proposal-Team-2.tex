\documentclass{article}
\usepackage[protrusion=true]{microtype}
\usepackage[sfdefault]{FiraSans}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[style=apa]{biblatex}
\usepackage{booktabs}
\usepackage{breqn}
\usepackage{enumitem}
\usepackage{float}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{lipsum}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{pdfpages}
\usepackage{pgfgantt}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{xcolor}

% set bibliography style to APA
\DeclareLanguageMapping{english}{english-apa}

% import bibliography file
\addbibresource{references.bib}

% page layout
\geometry{ letterpaper, left=1in, right=1in, top=1in, bottom=1in, }

% color scheme
\definecolor{primary}{RGB}{0,120,215}
\definecolor{secondary}{RGB}{255,87,34}
\definecolor{background}{RGB}{245,245,245}
\definecolor{blue}{RGB}{0,62,126}

% page color
\pagecolor{background}

% hyperlink colors
\hypersetup{ colorlinks=true, linkcolor=primary, filecolor=secondary, urlcolor=primary, citecolor=black }

% bibliography hyperlink colors
\AtBeginBibliography{\hypersetup{urlcolor=black}}

% line spacing
\setstretch{1.15}

% indent each reference by 0.5in on the second line
\setlength{\bibhang}{0.5in}

% put space between bibliography items
\setlength\bibitemsep{1.5\itemsep}

% no paragraph indentation
\setlength{\parindent}{0pt}

\begin{document}

\newcommand{\mytitlepage}[2]{
    \thispagestyle{empty}

    \begin{tikzpicture}[remember picture, overlay]
        \node [inner sep=0pt] at (current page.center) {#1}; { \node [ anchor=center, inner sep=1.25cm, rectangle, fill=blue!70!white, fill opacity=0, text opacity=1, minimum height=0.2\paperheight, minimum width=\paperwidth, text width=0.8\paperwidth, font=\fontfamily{pnc}\selectfont ] at (current page.center) {#2}; } \node [anchor=south east, outer sep=3pt] at (current page.south east) {\includegraphics[width=0.33\paperwidth]{images/logo.png}};
    \end{tikzpicture}

    \newpage
}

{ \mytitlepage{\includegraphics[width=\paperwidth]{images/background.png}} {
        \centering
        \fontfamily{phv}

        \vspace{-200pt} % move title up

        { \Huge
            \bfseries

            Brand Sentiment Analysis of\\
            Social Media Text Content

            \par
        }

        \vspace{8pt}

        { \Large
            \bfseries

            Proposal

            \par
        }

        \vspace{24pt}

        {
            \begin{center}
                \begin{tabular*} {\textwidth}{@{\extracolsep{\fill}}c c c} {\LARGE Jonathan Agustin} & {\LARGE Fernando Calderon} & {\LARGE Juliet Lawton}
                \end{tabular*}
            \end{center}
        } } }

\pagenumbering{arabic}

\textbf{Introduction.} Businesses increasingly leverage social media platforms to track brand perception using Natural Language Processing (NLP), Classification, and Sentiment Analysis (\cite{colleoni2011measuring, benedetto2016big}). Machine Learning (ML) models are trained with social media text content to classify a brand and categorize sentiment towards the brand as positive, negative, neutral, or mixed (\cite{alessia2015approaches, anupama2020real, vidya2015twitter}). The objective is to train a model using the Sentiment140 dataset to classify sentiment of textual tweets (\cite{go2009twitter, pak2010twitter}). We experiment with ML algorithms like Naïve Bayes and Logistic Regression to find the best fit (\cite{howard2018universal}). Ultimately, the proposed system will allow businesses to quickly react to shifts in public sentiment and maintain a positive brand image (\cite{vidya2015twitter, petasis2013large, ducange2019effective}). \\
\\
\textbf{Related Course Topics.} This project will cover various course topics, including Natural Language Processing, Supervised Machine Learning, Classification, Regression, Bayesian Networks, and Deep Learning (\cite{severyn2015twitter, liu2020aspect, socher2013recursive}).\\
\\
\textbf{Algorithms.} For this problem, the primary machine learning algorithms for consideration are Naïve Bayes, Logistic Regression, Support Vector Machines, Recurrent Neural Networks, and Transformers (like BERT) (\cite{DBLP:journals/corr/abs-1810-04805}).\\
\\
\textbf{Problem.} Given brand names $b_1 = \texttt{Nike}, b_2 = \texttt{Google}, b_3 = \texttt{Disney}, \dots, b_j \in B$ and Twitter posts
\begin{align*}
    p_1 & = \texttt{Celebrating my birthday}                      \\
    p_2 & = \texttt{I could care less about the new Air Force 1s} \\
    p_3 & = \texttt{Happiest place on Earth}                      \\
        & \vdots                                                  \\
    p_j & \in P
\end{align*}

the goal is to build a $\mathrm{BrandClassifier}(p)$ model that predicts whether a Twitter post $p$ expresses a brand and returns a brand name $b$ when the post expresses the brand or $\texttt{No-Brand}$ when the post does not express any brand. The model also returns a confidence score $c \in [0, 1]$ indicating confidence in prediction.

\[
    \mathrm{BrandClassifier}(p) \rightarrow \begin{cases}
        (b, c)                 & \text{if } p \text{ expresses a brand } b \in
        B
        \\
        (\texttt{No-Brand}, c) & \text{otherwise}
    \end{cases}
\]

We also build a $\mathrm{BrandSentimentAnalyzer}(p, b)$ model that predicts the sentiment of a Twitter post towards a brand, and returns a sentiment label

\[
    s \in S =
    \{
    s^{+}=\texttt{Positive},
    s^{-}=\texttt{Negative},
    s^{0}=\texttt{Neutral},
    s^{?}=\texttt{Mixed}
    \}
\]

when the post expresses sentiment towards the brand, or $\texttt{No-Sentiment}$ when it does not express any sentiment. The model also returns a confidence score $c \in [0, 1]$.

\[
    \mathrm{BrandSentimentAnalyzer}(p, b) \rightarrow \begin{cases}
        (s, c)                     & \text{if } p \text{ expresses sentiment }
        s \in S \text{ about brand } b \in B
        \\
        (\texttt{No-Sentiment}, c) & \text{otherwise}
    \end{cases}
\]

\newpage

\textbf{Example.} Given the following Twitter post $p_3 = \texttt{I could care less about the new Air Force 1s}$ and $b_3 = \texttt{Nike}$:
\begin{align*}
     & \mathrm{BrandClassifier}(p_3) \rightarrow (b_3, 0.68)               \\
     & \mathrm{BrandSentimentAnalyzer}(p_3, b_3) \rightarrow (s^{-}, 0.82)
\end{align*}
\\
\textbf{Methodology.} The work is divided into three stages: assessment, development, and evaluation. The process is circular---each stage informs and refines previous stages, creating a feedback loop that continuously improves the overall system.\\

\begin{enumerate}[leftmargin=*]

    \item \textbf{Assessment.} The stage involves analyzing the dataset and selecting and testing appropriate models. The specific requirements of the sentiment analysis task, the characteristics of the available data, and the nature of the problem guide this selection process.

    \item \textbf{Development.} This process involves handling invalid values and discarding non-textual content such as images, videos, or audio. Automation ensures efficiency in this process. The selected models are trained to identify a brand or align with the sentiment expressed in a tweet, and then tuned to improve performance.

    \item \textbf{Evaluation.} This stage measures the models' ability to identify brands and predict sentiment in Twitter posts. The tweets used for validation can come from a test set partitioned from the original dataset, as well as from the Twitter API. Standard classification metrics such as Accuracy, Precision, Recall, and F1 Score are used to evaluate the models. The models are then ranked by performance.

\end{enumerate}

\textbf{Expected Behaviors.} Our models are aimed to have a nuanced understanding of language. We expect an accuracy rate over 50\%. Overall, our models will probably have real-world applicability, serving as a valuable tool for businesses to accurately predict sentiment from social media data. Ultimately, the proposed system is expected to provide actionable insights that enable companies to make informed decisions.\\
\\
\textbf{Known Challenges} A well-known problem in sentiment analysis is the ``aboutness'' problem. This problem refers to the challenge of determining the subject of the sentiment expressed in a sentence. For our scenario, this may manifest in one of two ways---complex sentences and ambiguous subjects. Take for example the sentence ``I love Disneyland but hate how expensive the tickets are.'' This sentence expresses both positive and negative sentiment towards the brand, Disney, but the overall sentiment is positive. In the second scenario, take for example the sentences ``Google is a great company'' and ``You should google that.'' The first sentence refers to Google the brand with positive sentiment, and the second sentence refers to google as a verb and should not be regarded as an expression of sentiment towards the brand. \\
\\
\textbf{Limitations} The primary limitation of the model is that it is trained on Twitter posts, so it cannot classify posts from other social media sites, such as Facebook. Another limitation is the unimodal nature of the model. It processes only text data, ignoring non-textual elements like images, videos, and audio clips. Often found in social media posts, these elements can have significant sentiment-related information. This information can support, contradict, or add nuance to the sentiment expressed in the text. Audio clips, for example, can provide sentiment-related cues through tone, pitch, and other features. Future work should generalize the model to work with other kinds of social media posts, as well as expanding the model to a multimodal framework to provide a more comprehensive sentiment analysis of social media posts.

\newpage

\thispagestyle{empty}

\printbibliography

\end{document}